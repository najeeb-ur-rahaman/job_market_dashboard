# üíº UK Job Market Analysis (Cloud Version)

An end-to-end data pipeline that collects, processes, stores, and visualizes UK tech job data using the [Adzuna API](https://developer.adzuna.com/). Built with **Apache Airflow**, **Python**, **Neon (PostgreSQL)**, and **Streamlit**.

## üß© Features

- üîÑ Daily job data ingestion via Adzuna API
- üß† Automatic skill extraction using `facebook/bart-large-mnli` model
- üóÉÔ∏è Data stored in Neon PostgreSQL (cloud database)
- üìä Interactive dashboard with filters and insights using Streamlit
- üìÖ Backfill-safe design (fetches yesterday‚Äôs data)

## üì∑ Preview

![Dashboard Screenshot](assets/dashboard-overview.jpg)

## üîß Architecture Overview

![Architechture Screenshot](assets/architechture.png)

## üóÇÔ∏è Project Structure

```
job\_market\_dashboard/
‚îÇ
‚îú‚îÄ‚îÄ dags/                      # Airflow DAG scripts
‚îÇ   ‚îî‚îÄ‚îÄ job\_market\_dag.py
‚îÇ
‚îú‚îÄ‚îÄ datasets/                  # Local storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Raw JSON data
‚îÇ   ‚îî‚îÄ‚îÄ processed/             # Transformed CSV files
‚îÇ
‚îú‚îÄ‚îÄ api_client.py
‚îú‚îÄ‚îÄ dashboard.py
‚îú‚îÄ‚îÄ jobs_table.py
‚îú‚îÄ‚îÄ skill_extractor.py
‚îú‚îÄ‚îÄ skills.py
‚îú‚îÄ‚îÄ task1.py
‚îú‚îÄ‚îÄ task2.py
‚îú‚îÄ‚îÄ utils.py
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml         # Multi-service Docker setup
‚îú‚îÄ‚îÄ .env.example               # Sample environment config
‚îî‚îÄ‚îÄ README.md
```

## üîê Environment Variables

Create a `.env` file in your project root:

```env
# Adzuna API
ADZUNA_APP_ID=your_app_id
ADZUNA_APP_KEY=your_api_key

# Neon PostgreSQL Connection String
NEON_URL=postgresql://username:password@your-project.neon.tech/dbname
```

> üîí **Never commit your `.env` file to GitHub.**

## ‚öôÔ∏è Airflow DAG Details

- **Frequency**: Daily
- **Logic**: Pulls **yesterday‚Äôs** jobs to ensure complete data
- **Tasks**:

  - `fetch_and_save_to_csv`: Pulls from API, transforms JSON to CSV
  - `load_csv_to_db`: Extracts skills using BART model & uploads to Neon DB

> ‚úÖ The jobs table is stored in `job_market.job_market_db.dev.jobs`

## üßæ Neon PostgreSQL Table Schema

```sql
    jobs = Table(
        "jobs", metadata,
        Column("job_id", String(50), primary_key=True),
        Column("title", String(255)),
        Column("company", String(255)),
        Column("contract_type", String(50)),
        Column("contract_time", String(50)),
        Column("created", DateTime),
        Column("location", String(255)),
        Column("category", String(100)),
        Column("salary_min", Float),
        Column("salary_max", Float),
        Column("skills", Text),
        Column("description", Text),
        Column("timestamp", DateTime),
    )
```

## üìä Dashboard Filters

- Filter by **single date** or **date range**
- Visual insights:

  - üîù Top 20 Skills
  - üí∞ Salary Distribution
  - üìç Top Locations
  - üìà Jobs Over Time

## ‚ñ∂Ô∏è Running Locally

> Requires Docker and Docker Compose installed.

```bash
docker-compose up --build
```

- Access Airflow UI: [http://localhost:8080](http://localhost:8080)
- Access Streamlit Dashboard: [http://localhost:8501](http://localhost:8501)

## üõ†Ô∏è Tech Stack

- **Airflow** for orchestration
- **Python** (pandas, requests, transformers)
- **HuggingFace Transformers** for skill extraction
- **Neon PostgreSQL** for cloud DB
- **Streamlit** for dashboarding
- **Docker** for containerization

## üßë‚Äçüíª Author

**Najeeb ur Rahaman**
[GitHub](https://github.com/najeeb-ur-rahaman) | [LinkedIn](https://www.linkedin.com/in/snajeebr)
